Normalizacos = {
    "Linear":{
        "Descri√ß√£o":" Transforma os dados para um intervalo espec√≠fico, geralmente [0, 1], preservando a distribui√ß√£o original. Muito √∫til quando voc√™ sabe os valores m√°ximos e m√≠nimos de antem√£o.",
        "Formula":"x' = \frac{x - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}}",
    },
    "Z-Score Scaling":{
        "Descri√ß√£o":"Valor M√°ximo",
        "Formula":"z = \frac{x - \mu}{\sigma}",
    },
    " Max-Min":{
        "Descri√ß√£o":"Cria os valores de acordo com um dadado espa√ßo numerico do seu agrado por padr√£o √© [0,1] porem pode ser um que seja definido pelo usu√°rio.",
        "Formula":"f(X) = \frac{X - min_X}{max_X - min_X} \times (novo\_max_X - novo\_min_X) + novo\_min_X",
    },
    "Valor M√°ximo":{
        "Descri√ß√£o":"Escala os dados pelo valor absoluto m√°ximo, mantendo a dispers√£o e lidando bem com dados esparsos.",
        "Formula":"x' = \frac{x}{|x_{\text{max}}|}",
    },
    "Robust Scaling":{
        "Descri√ß√£o":"Subtrai a mediana e divide pelo intervalo interquartil (IQR), sendo robusto a outliers e √∫til para dados que n√£o seguem distribui√ß√µes normais.",
        "Formula":"x' = \frac{x - \text{mediana}(x)}{IQR(x)}",
    },
    "Decimal Scaling":{
        "Descri√ß√£o":"Move os dados para uma escala onde o valor absoluto m√°ximo est√° entre [0, 1]. √â √∫til quando os dados variam em m√∫ltiplas ordens de grandeza.",
        "Formula":"x' = \frac{x}{10^j}",
    },
    "L2 Normalization":{
        "Descri√ß√£o":"Escala os vetores de forma que sua norma ùêø2 seja 1. Muito usada em m√©todos de aprendizado de m√°quina baseados em dist√¢ncia, como SVM e k-NN.",
        "Formula":"x' = \frac{x}{\sum |x_i|}",
    },
    "L1 Normalization":{
        "Descri√ß√£o":"Normaliza os dados de forma que a soma dos valores absolutos de cada ponto seja igual a 1. √ötil quando se lida com dados esparsos.",
        "Formula":"x' = \frac{x}{\sum |x_i|}",
    },
    "Logarithmic Transformation":{
        "Descri√ß√£o":"Usada para lidar com dados que seguem uma distribui√ß√£o exponencial, tornando-os mais normais. √â sens√≠vel a valores pr√≥ximos de zero, ent√£o frequentemente √© adicionada uma constante.",
        "Formula":"x' = \log(x + 1)",
    },
    "Sigmoid Normalization":{
        "Descri√ß√£o":"Mapeia os valores em um intervalo entre 0 e 1. √â amplamente utilizada em redes neurais.",
        "Formula":"x' = \frac{1}{1 + e^{-x}}",
    },
    "Tanh Estimator Scaling ":{
        "Descri√ß√£o":"Uma transforma√ß√£o robusta que mapeia os dados para o intervalo [0, 1], baseada na fun√ß√£o tangente hiperb√≥lica, √∫til em redes neurais profundas.",
        "Formula":"x' = 0.5 \times \left(1 + \tanh\left(0.01 \times (x - \mu)\right)\right)",
    },
    "Power Transformations":{
        "Descri√ß√£o":"Generaliza√ß√£o da Box-Cox para dados que cont√™m valores negativos. Essas transforma√ß√µes estabilizam a vari√¢ncia e tornam os dados mais gaussianos.",
        "Formula":"x' = \frac{x^{\lambda} - 1}{\lambda}",
    },
    
    
}